# BETO is Spanish BERT

In this repo we open-source our SpanishBERT model. 

# Download

### Tensorflow

Uncased BETO ([vocab](https://users.dcc.uchile.cl/~jperez/beto/vocab.txt), [config](https://users.dcc.uchile.cl/~jperez/beto/bert_config.json), [weights](https://users.dcc.uchile.cl/~jperez/beto/tensorflow_weights.tar.gz))

Cased BETO ([vocab](www.google.com), [config](www.google.com), [weights](www.google.com)) - Coming soon!

### PyTorch

Uncased BETO ([vocab](https://users.dcc.uchile.cl/~jperez/beto/vocab.txt), [config](https://users.dcc.uchile.cl/~jperez/beto/bert_config.json), [weights](https://users.dcc.uchile.cl/~jperez/beto/pytorch_weights.tar.gz))

Cased BETO ([vocab](www.google.com), [config](www.google.com), [weights](www.google.com)) - Coming soon!

# Example of use

For further details you can visit the amazing [ðŸ¤— Transformers](https://github.com/huggingface/transformers) repo.

# Evaluation

This is WIP: For now you can visit [beto-benchmarking](https://github.com/josecannete/beto-benchmarking) to see the progress.

# Training details

### Corpora

We used the Spanish Unnanotated Corpora to train. For further details please visit the respective repo: [SUC](https://github.com/josecannete/spanish-corpora)

### Vocabulary

# Acknowledgments

# FAQ

